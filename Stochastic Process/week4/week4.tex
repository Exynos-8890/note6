\documentclass[en,hazy,blue,12pt,device = normal]{elegantnote}
\usepackage[breakable]{tcolorbox}
\usepackage{amsmath,amsthm,amssymb,bm,xcolor}
\usepackage{../spdefs}
\tcbset{breakable}
\setcounter{MaxMatrixCols}{13}
\pagecolor{white}

\title{Stochastic Process week 3 Exercise}
\author{Tianlu Zhu \\ 2020571005}
% \institute{ShanghaiTech}
\date{}
\begin{document}
\maketitle

Chap 4: 20, 22, 23, 32, 38, 45, 47

\begin{enumerate}
    \item[20] A transition probability matrix \({\textbf P}\) is said to be doubly stochastic is the sum over each column equals one; that is,
    \[\sum _i P_{ij } = 1, \quad \text{for all } j  \] 
    If such a chain is irreducible and consists of \(M+1\) states \(0,1,\cdots,M\), show that the long-run proportions are given by 
    \[\pi_j = \frac{1}{M+1},\quad j = 0,1,\cdots,M\]
    \begin{tcolorbox}
        \sol 

        Since that \(\pi = \pi \textbf P\), for all \(j \) we have:
        \begin{align*}
            \begin{cases}
                \pi _j = \sum _i \pi_i P_{ij },\quad \forall j\\
                \sum_iP_{ij } = \sum_j P_{ij } = 1\\
                \sum_i \pi_i = 1
            \end{cases}
        \end{align*}
        % Sum up \(j \):
        % \begin{align*}
        %     \sum_j \pi_j = \sum_j \sum _i \pi_i P_{ij } = \sum_i\pi_i \sum_j P_{ij } = \sum_i \pi_i 
        % \end{align*}
    \end{tcolorbox}
    \item[22] Let \(Y_n\) be the sum of \(n\) independent rolls of a fair die. Find
    \begin{align*}
        \lim_{n\to\infty} P\left\{ Y_n \text{ is a multiple of 13 } \right\}
    \end{align*}
    
    \begin{tcolorbox}
        \sol

        Let \(\pi_1 = (0,1/6,1/6,1/6,1/6,1/6,1/6,0,0,0,0,0,0)\) and The transition matrix is:
        {\begin{align*}
            \footnotesize
            \textbf P = 
            \begin{bmatrix}
                0&1/6&1/6&1/6&1/6&1/6&1/6&0&0&0&0&0&0 \\
                0&0&1/6&1/6&1/6&1/6&1/6&1/6&0&0&0&0&0 \\
                0&0&0&1/6&1/6&1/6&1/6&1/6&1/6&0&0&0&0 \\
                0&0&0&0&1/6&1/6&1/6&1/6&1/6&1/6&0&0&0 \\
                0&0&0&0&0&1/6&1/6&1/6&1/6&1/6&1/6&0&0 \\
                0&0&0&0&0&0&1/6&1/6&1/6&1/6&1/6&1/6&0 \\
                0&0&0&0&0&0&0&1/6&1/6&1/6&1/6&1/6&1/6 \\
                1/6&0&0&0&0&0&0&0&1/6&1/6&1/6&1/6&1/6 \\
                1/6&1/6&0&0&0&0&0&0&0&1/6&1/6&1/6&1/6 \\
                1/6&1/6&1/6&0&0&0&0&0&0&0&1/6&1/6&1/6 \\
                1/6&1/6&1/6&1/6&0&0&0&0&0&0&0&1/6&1/6 \\
                1/6&1/6&1/6&1/6&1/6&0&0&0&0&0&0&0&1/6 \\
                1/6&1/6&1/6&1/6&1/6&1/6&0&0&0&0&0&0&0
            \end{bmatrix}
        \end{align*}}
        Which satisfy exercise 20. Then for a stationary distribution \(\pi_i = \frac{1}{13}\)
    \end{tcolorbox}
    
    \item[23] In a good weather year the number of storms is Poisson distributed with mean 1; in a bad year it is Poisson distributed with mean 3. Suppose that any year's weather conditions depends on past years only through the previous year's condition. Suppose that a good year is equally likely to be followed by either a good or a bad year, and that a bad year is twice as likely to be followed by a bad year as by a good year. Suppose that last year-call it year 0-was a good year.
    
    (a) Find the expected total number of storms in the next two years (that is, in years 1 and 2).

    (b) Find the probability there are no storms in year 3.

    (c) Find the long-run average number of storms per year.

    (d) Find the proportion of years that have no storms.
    
    \begin{tcolorbox}
        \sol

        Let \(X_i, i = 0,1,2,\cdots\) denote the weather, \(0\) for good and \(1\) for bad weather. The transition matrix is
        \begin{align*}{\bf P} = 
            \begin{bmatrix}
                1/2&1/2\\
                1/3&2/3
            \end{bmatrix}
        \end{align*}
        And \(\pi_0 = (1,0)\). Let \(Y_i\) denote the \#storms of year \(i\), and 
        \begin{align*}
            Y_i|X_i \sim \begin{cases}
                \operatorname{Pois}(1),\quad X_i = 0 \\
                \operatorname{Pois}(3),\quad X_i = 1
            \end{cases}
        \end{align*}
        \begin{enumerate}[(a)]
            \item \begin{align*}
                &\mean{Y_1+Y_2} \\
                =& \mean{Y_1} + \mean{Y_2}\\
                =& p_{00} \times 1 + p_{01} \times 3 + \left( p_{00}^2  + p_{01}p_{10} \right) \times 1 + \left( p_{00}p_{01} + p_{01}p_{11} \right) \times 3 \\
                =& \frac{25}{6}
            \end{align*}
            \item \begin{align*}
                &P(Y_3 = 0) \\
                =&P(Y_3 = 0|X_3 = 0) P(X_3 = 0) + P(Y_3 = 0|X_3 = 1) P(X_3 = 1) \\
                =& e^{-1} (p_{00}^3 + 2p_{00}p_{01}p_{10}+ p_{01}p_{11}p_{10})+e^{-3} (3p_{00}^2p_{01}+p_{01}^2p_{10})\\
                =& \frac{29}{72} e^{-1} + \frac{11}{24} e^{-3}
            \end{align*}
            \item Let \(\pi = {\bf P} \pi\), \(\pi = (2/5,3/5)\). So,
            \begin{align*}
                \mean{Y} &= \mean{Y|X=0}P(X=0) + \mean{Y|X=1} P(X=1) \\
                &= 1\times \frac 2 5 + 3\times \frac 3 5 = \frac{11}{5}
            \end{align*}
            \item \begin{align*}
                &P(Y = 0) \\
                =& P(Y = 0 | X = 0) P(X=0) + P(Y = 0|X=1)P(X=1) \\
                =& \frac 2 5 e^{-1} + \frac 3 5 e^{-3}
            \end{align*}
        \end{enumerate}
    \end{tcolorbox}

    \item[32] Each of two switches is either on or off during a day. On day \(n\), each switch will independently be on with probability
    \begin{center}
        \([1+\) number of on switches during day \(n-1] / 4\)
    \end{center}
    For instance, if both switches are on during day \(n-1\), then each will independently be on during day \(n\) with probability \(3 / 4\). What fraction of days are both switches on? What fraction are both off?
    \begin{tcolorbox}
        \sol

        % Let the state probability be \(\pi\) that \(\pi = P\)
        There are three state:0,1,2 switch(es) is on. So, the probability vector be \(\pi\), the transition matrix is 
        \begin{align*}
            {\bf P} = \begin{bmatrix}
                9/16 & 6/16 & 1/16 \\
                1/4 & 1/2&1/4 \\
                1/16 & 6/16 & 9/16 
            \end{bmatrix}
        \end{align*}
        The stationary distribution is \(\pi = (3/8,1/4,3/8)\).
    \end{tcolorbox}
    \item[38] Capa plays either one or two chess games every day, with the number of games that she plays on successive days being a Markov chain with transition probabilities
    \begin{align*}
    P_{1,1}=.2, \quad P_{1,2}=.8 \quad P_{2,1}=.4, \quad P_{2,2}=.6
    \end{align*}
    Capa wins each game with probability \(p\). Suppose she plays two games on Monday.

    (a) What is the probability that she wins all the games she plays on Tuesday?

    (b) What is the expected number of games that she plays on Wednesday?

    (c) In the long run, on what proportion of days does Capa win all her games.

    \begin{tcolorbox}
        \sol

        \begin{enumerate}[(a)]
            \item \[P = P_{11}p+P_{12}p^2 = 0.2p+0.8p^2\]
            \item \[E(X) = 1\times\left( P_{11}^2 + P_{12}P_{21} \right) + 2\times \left( P_{12}P_{22} + P_{11}P_{12} \right) = 1.48\]
            \item Let \(\pi\) denote the stationary distribution, \(\pi = \pi{\bf P} \). Then \(\pi = (1/3,2/3)\)
        \end{enumerate}
    \end{tcolorbox}
    \item[45] Consider an irreducible finite Markov chain with states \(0,1,\cdots N\).
    \begin{enumerate}[(a)]
        \item  Starting in state \(i\), what is the probability the process will ever visit state \(j \)? Explain.
        \item Let \(x_i = P\{\text{visit state N before state } 0 | \text{start in }i\}\). Compute a set of linear equations that the \(x_i\) satisfy \(i = 0,1,\cdots,N\).
        \item If \(\sum_j jP_{ij } = i\) for \(i = 1,\cdots,N-1\), show that \(x_i = i/N\) is a solution to the equations in part (b).
    \end{enumerate}
    \begin{tcolorbox}
        \sol
        \begin{enumerate}[(a)]
            \item Let the first visit probability in time \(t\) be \(f_{ij }^t\), the acquiring probability is \(\sum_{t = 1}^\infty f_{ij }^t\).
            \item \begin{align*}
                \begin{cases}
                    x_0 = 0 \\
                    x_N = 1 \\
                    x_i = \sum_j jP_{ij } / N
                \end{cases}
            \end{align*}
            % \item 
        \end{enumerate}
    \end{tcolorbox}

    \item[47] Let \(\left\{ X_n,n\geq 0  \right\}\) denote an ergodic Markov chain with limiting probabilities \(\pi_i \). Define the process \(\left\{ Y_n,n\geq 1 \right\}\) by \(Y_n = (X_{n-1},X_n)\). That is, \(Y_n\) keeps track of the last two states of the original chain. Is \(\left\{ Y_n,n\geq 1 \right\}\) a Markov chain? If so, determine its transition probabilities and find 
    \[\lim_{n\to \infty}P\left\{ Y_n = (i,j ) \right\}\]
    \begin{tcolorbox}
        \sol

        It is a Markov chain. To show that, \(Y_n\) only depends on \(X_n\), and can be derived from \(y_{n-1}\).
        \begin{align*}
            \lim_{n\to \infty}P\left\{ Y_n = (i,j ) \right\} = |\pi_j - \pi_i|
        \end{align*}

        % \begin{align*}
        %     P(Y_n = y_n | )
        % \end{align*}
    \end{tcolorbox}
\end{enumerate}

\end{document}